{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69bc90b9-d5d4-4f77-94bd-90a463aad2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71a27599-0683-402f-b29a-6aa2b90156cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/n/holylabs/LABS/kempner_fellows/Users/binxuwang/Github/edm\")\n",
    "# torch_utils is needed from this path. \n",
    "sys.path.append(\"/n/home12/binxuwang/Github/mini_edm\")\n",
    "sys.path.append(\"/n/home12/binxuwang/Github/DiffusionMemorization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4ceb681-0520-481e-9f61-7d4a9c523f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import re \n",
    "import glob\n",
    "import os\n",
    "from os.path import join\n",
    "import torch\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from generate import edm_sampler\n",
    "# from core.edm_utils import edm_sampler\n",
    "# from train_edm import create_model, edm_sampler\n",
    "from torchvision.utils import make_grid, save_image\n",
    "from torchvision.transforms import ToPILImage\n",
    "\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "beb28c1d-9636-4325-a033-1e081f47f8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_root = \"/n/holylabs/LABS/kempner_fellows/Users/binxuwang/Github/edm/training-runs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f20bf66-1b9b-4bc0-84e1-4aec2c68c400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240M\t00004-afhqv2-64x64-uncond-ncsnpp-edm-gpus1-batch64-fp32\n",
      "1.7G\t00013-afhqv2-64x64-uncond-ncsnpp-edm-gpus4-batch768-fp16\n",
      "237M\t00017-afhqv2-64x64-uncond-ddpmpp-edm-gpus4-batch256-fp32\n",
      "237M\t00018-afhqv2-64x64-uncond-ddpmpp-edm-gpus4-batch392-fp32\n",
      "4.2G\t00019-afhqv2-64x64-uncond-ddpmpp-edm-gpus4-batch256-fp32\n",
      "4.2G\t00020-ffhq-64x64-uncond-ddpmpp-edm-gpus4-batch256-fp32\n",
      "6.5G\t00021-afhqv2-64x64-whitened-nonorm-uncond-ddpmpp-edm-gpus4-batch256-fp32\n",
      "6.5G\t00022-afhqv2-64x64-whitened-uncond-ddpmpp-edm-gpus4-batch256-fp32\n",
      "6.5G\t00023-ffhq-64x64-whitened-uncond-ddpmpp-edm-gpus4-batch256-fp32\n",
      "6.5G\t00024-ffhq-64x64-whitened-nonorm-uncond-ddpmpp-edm-gpus4-batch256-fp32\n",
      "6.5G\t00028-afhqv2-64x64-spectral-whiten-uncond-ddpmpp-edm-gpus4-batch256-fp32\n",
      "6.5G\t00029-ffhq-64x64-spectral-whiten-uncond-ddpmpp-edm-gpus4-batch256-fp32\n",
      "3.3G\t00030-afhqv2-64x64-uncond-ddpmpp-edm-gpus4-batch256-fp32\n",
      "3.3G\t00031-ffhq-64x64-uncond-ddpmpp-edm-gpus4-batch256-fp32\n",
      "12G\t00032-cifar10-32x32-uncond-ddpmpp-edm-gpus4-batch256-fp32\n",
      "12G\t00033-cifar10-32x32-cond-ddpmpp-edm-gpus4-batch256-fp32\n",
      "13G\t00034-afhqv2-64x64-uncond-ddpmpp-edm-gpus4-batch256-fp32\n",
      "13G\t00035-ffhq-64x64-uncond-ddpmpp-edm-gpus4-batch256-fp32\n"
     ]
    }
   ],
   "source": [
    "!cd /n/holylabs/LABS/kempner_fellows/Users/binxuwang/Github/edm/training-runs ; du -sh *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f440a6b-f48c-4065-9723-481339bd4b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/n/holylabs/LABS/kempner_fellows/Users/binxuwang/Github/edm\")\n",
    "def load_edm_model(ckptdir, ckpt_idx=-1, train_root=train_root, return_epoch=False):\n",
    "    ckpt_list = glob.glob(join(train_root, ckptdir, \"*.pkl\"))\n",
    "    ckpt_list = sorted(ckpt_list)\n",
    "    ckpt_path = ckpt_list[ckpt_idx]\n",
    "    epoch = int(re.findall(r'-(\\d+).pkl', ckpt_path)[-1])\n",
    "    print(f\"Loading {ckpt_idx}th ckpt\", ckpt_path)\n",
    "    print(\"Epoch \", epoch)\n",
    "    with open(ckpt_path, 'rb') as f:\n",
    "        net = pkl.load(f)['ema'].to(device)\n",
    "    if return_epoch:\n",
    "        return net, epoch\n",
    "    else:\n",
    "        return net\n",
    "    \n",
    "\n",
    "\n",
    "def load_stats(ckptdir, train_root=train_root):\n",
    "    train_stats = []\n",
    "    with open(join(train_root, ckptdir, \"stats.jsonl\")) as f:\n",
    "        for line in tqdm(f):\n",
    "            train_stats.append(json.loads(line))\n",
    "    return pd.DataFrame(train_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c8d1a9-c46b-4267-bd51-ca97ac1a692a",
   "metadata": {},
   "source": [
    "### Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "555cdfdf-b0ad-4723-b2ee-8b54eb7d6800",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.dataset import ImageFolderDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34e7472e-c6ca-4542-955f-b919918d1cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "afhqv2-64x64-eigen.pt\t\t  ffhq-64x64-eigen.pt\n",
      "afhqv2-64x64-spectral-whiten.pt   ffhq-64x64-spectral-whiten.pt\n",
      "afhqv2-64x64-whitened-nonorm.zip  ffhq-64x64-whitened-nonorm.zip\n",
      "afhqv2-64x64-whitened.zip\t  ffhq-64x64-whitened.zip\n",
      "afhqv2-64x64.zip\t\t  ffhq-64x64.zip\n",
      "cifar10-32x32.zip\n"
     ]
    }
   ],
   "source": [
    "!ls /n/holylabs/LABS/kempner_fellows/Users/binxuwang/Github/edm/datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "512b5c3f-fe9a-4918-84e8-e92c68effbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot = \"/n/holylabs/LABS/kempner_fellows/Users/binxuwang/Github/edm/datasets\"\n",
    "dataset_afhq = ImageFolderDataset(join(dataroot, \"ffhq-64x64.zip\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d31ddbd-4fe2-4ec7-bbfd-97bb567924fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtsr = np.stack([sample for sample, _ in dataset_afhq], axis=0) # (N, C, H, W)\n",
    "Xtsr = torch.from_numpy(Xtsr)\n",
    "Xtsr_norm = Xtsr / 127.5 - 1 # convention of edm model \n",
    "edm_Xmat = Xtsr_norm.view(Xtsr_norm.shape[0], -1)\n",
    "edm_Xmat = edm_Xmat.to(device)\n",
    "edm_Xmean = edm_Xmat.mean(dim=0)\n",
    "edm_Xcov = (edm_Xmat - edm_Xmean).T @ (edm_Xmat - edm_Xmean) / edm_Xmat.shape[0]\n",
    "eigvals, eigvecs = torch.linalg.eigh(edm_Xcov)\n",
    "eigvals = eigvals.flip(0)\n",
    "eigvecs = eigvecs.flip(1)\n",
    "edm_imgshape = Xtsr.shape[1:]\n",
    "edm_std_mean = (torch.trace(edm_Xcov) / edm_Xcov.shape[0]).sqrt()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28282994-7438-4f2c-af9d-909c9164eed4",
   "metadata": {},
   "source": [
    "### Clustering structure of AFHQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f2c8ce1-3fb5-4b70-897a-7eb7e4cba8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.analytical_score_lib import mean_isotropic_score, Gaussian_score, delta_GMM_score\n",
    "from core.analytical_score_lib import explained_var_vec\n",
    "from core.analytical_score_lib import sample_Xt_batch, sample_Xt_batch\n",
    "from core.gaussian_mixture_lib import gaussian_mixture_score_batch_sigma_torch, \\\n",
    "    gaussian_mixture_lowrank_score_batch_sigma_torch, compute_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edb372d5-26aa-4e0b-8e2a-780f4d48e981",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/home12/binxuwang/.conda/envs/torch/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1930: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans fitting completing, loss  31556048.80640143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [02:46<00:00,  8.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cov PCA completed for each cluster.\n",
      "n_clusters=20, computed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/home12/binxuwang/.conda/envs/torch/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1930: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans fitting completing, loss  33712946.7767118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [01:37<00:00,  9.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cov PCA completed for each cluster.\n",
      "n_clusters=10, computed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/home12/binxuwang/.conda/envs/torch/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1930: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans fitting completing, loss  36387242.270318665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [01:04<00:00, 12.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cov PCA completed for each cluster.\n",
      "n_clusters=5, computed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/home12/binxuwang/.conda/envs/torch/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1930: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans fitting completing, loss  40646453.04290734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:43<00:00, 21.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cov PCA completed for each cluster.\n",
      "n_clusters=2, computed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/home12/binxuwang/.conda/envs/torch/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1930: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans fitting completing, loss  45597426.595639005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:37<00:00, 37.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cov PCA completed for each cluster.\n",
      "n_clusters=1, computed.\n"
     ]
    }
   ],
   "source": [
    "kmeans_batch = 2048\n",
    "kmeans_random_seed = 42\n",
    "kmeans_verbose = 0\n",
    "lambda_EPS = 1E-5\n",
    "Us_col = {}\n",
    "mus_col = {}\n",
    "Lambdas_col = {}\n",
    "weights_col = {}\n",
    "for n_clusters in reversed([1, 2, 5, 10, 20,]): #  50, 100, \n",
    "    kmeans, eigval_mat, eigvec_mat, freq_vec, center_mat = compute_cluster(edm_Xmat.cpu(), \n",
    "                            n_clusters=n_clusters,\n",
    "                            kmeans_batch=kmeans_batch, \n",
    "                            kmeans_random_seed=kmeans_random_seed,\n",
    "                            kmeans_verbose=kmeans_verbose,\n",
    "                            lambda_EPS=lambda_EPS)\n",
    "    Us_col[n_clusters] = eigvec_mat #.to(device)\n",
    "    mus_col[n_clusters] = center_mat #.to(device)\n",
    "    Lambdas_col[n_clusters] = eigval_mat #.to(device)\n",
    "    weights = freq_vec / freq_vec.sum()\n",
    "    weights_col[n_clusters] = weights #.to(device)\n",
    "    print(f\"n_clusters={n_clusters}, computed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25e7d6a-9872-4aab-a233-c0d4a1259d0a",
   "metadata": {},
   "source": [
    "### Mass compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b336c5-f7fe-4e75-b1a7-e80530b38821",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from tqdm import trange\n",
    "from functools import partial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8d2c33-eb73-4a7c-8f6b-329f6f43cc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_func_col = {\n",
    "    \"mean isotropic\": lambda Xt, sigma: mean_isotropic_score(Xt, edm_Xmean, sigma).cpu(), \n",
    "    \"mean + std isotropic\": lambda Xt, sigma: mean_isotropic_score(Xt, edm_Xmean, sigma, sigma0=edm_std_mean).cpu(), \n",
    "    \"gaussian\": lambda Xt, sigma: Gaussian_score(Xt, edm_Xmean, edm_Xcov, sigma).cpu(), \n",
    "    \"gaussian regularize\": lambda Xt, sigma: Gaussian_score(Xt, edm_Xmean, edm_Xcov + torch.eye(edm_Xcov.shape[0]).to(device) * 1E-4, sigma).cpu(), \n",
    "    \"gmm delta\": lambda Xt, sigma: delta_GMM_score(Xt, edm_Xmat, sigma).cpu(), \n",
    "}\n",
    "# for n_clusters in reversed([1, 2, 5, 10, 20,]): #  50, 100, \n",
    "#     score_func_col[f\"gmm {n_clusters} mode\"] = lambda Xt, sigma: gaussian_mixture_score_batch_sigma_torch(Xt, \n",
    "#                 mus_col[n_clusters].cuda(), Us_col[n_clusters].cuda(), Lambdas_col[n_clusters].cuda() + sigma**2, \n",
    "#                 weights=weights_col[n_clusters].cuda()).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101c1421-7ec3-45f8-be00-578e1db8bb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckptname = \"00035-ffhq-64x64-uncond-ddpmpp-edm-gpus4-batch256-fp32\"\n",
    "device = \"cuda\"\n",
    "batch_size = 256\n",
    "Nreps = 4\n",
    "ckpt_num = len(glob.glob(join(train_root, ckptname, \"*.pkl\")))\n",
    "print(\"Explaining EDM score with GMM and other analytical scores\")\n",
    "df_col = []\n",
    "for ckpt_idx in trange(ckpt_num):\n",
    "    edm, epoch = load_edm_model(ckptname, ckpt_idx=ckpt_idx, return_epoch=True)\n",
    "    edm.to(device).eval();\n",
    "    print(f\"ckpt_idx={ckpt_idx}, epoch={epoch}\")\n",
    "    for sigma in [0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 0.75, 1.0, 1.5, 2.0, 5.0, 10.0, 20.0, 30.0, 40.0, 80.0]:\n",
    "        Xt_col = []\n",
    "        score_vec_col = defaultdict(list)\n",
    "        for rep in trange(Nreps, desc=f\"sigma {sigma} rep\"):\n",
    "            Xt = sample_Xt_batch(edm_Xmat, batch_size, sigma=sigma).to(device)\n",
    "            with torch.no_grad():\n",
    "                edm_Dt = edm(Xt.view(-1, *edm_imgshape), torch.tensor(sigma).cuda(), None, ).detach().cpu()\n",
    "            edm_Dt = edm_Dt.view(Xt.shape)\n",
    "            score_edm = (edm_Dt - Xt.cpu()) / (sigma**2)\n",
    "            score_vec_col[\"EDM\"].append(score_edm)\n",
    "            Xt_col.append(Xt.cpu())\n",
    "            for score_name, analy_score_func in score_func_col.items():\n",
    "                score_vec_col[score_name].append(analy_score_func(Xt, sigma))\n",
    "            for n_clusters in reversed([1, 2, 5, 10, 20,]): #  50, 100, \n",
    "                gmm_scores = gaussian_mixture_score_batch_sigma_torch(Xt, \n",
    "                    mus_col[n_clusters].cuda(), Us_col[n_clusters].cuda(), Lambdas_col[n_clusters].cuda() + sigma**2, \n",
    "                    weights=weights_col[n_clusters].cuda()).cpu()\n",
    "                score_vec_col[f\"gmm_{n_clusters}_mode\"].append(gmm_scores)\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        Xt_all = torch.cat(Xt_col, dim=0).cuda()\n",
    "        for score_name, score_vec_list in score_vec_col.items():\n",
    "            score_vec_col[score_name] = torch.cat(score_vec_list, dim=0)\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        score_edm = score_vec_col[\"EDM\"].cuda()\n",
    "        edm_Dt = score_edm * (sigma**2) + Xt_all\n",
    "        for score_name, score in score_vec_col.items():\n",
    "            score = score.to(device)\n",
    "            Dnoiser = score * (sigma**2) + Xt_all\n",
    "            exp_var_vec = explained_var_vec(score_edm, score)\n",
    "            exp_var_rev_vec = explained_var_vec(score, score_edm)\n",
    "            exp_var_vec_Dt = explained_var_vec(edm_Dt, Dnoiser)\n",
    "            exp_var_rev_vec_Dt = explained_var_vec(Dnoiser, edm_Dt)\n",
    "            St_var_vec = score.pow(2).sum(dim=1)\n",
    "            Dt_var_vec = Dnoiser.pow(2).sum(dim=1)\n",
    "            df_col.append({\"epoch\": epoch, \"sigma\": sigma, \"name\": score_name, \n",
    "                        \"St_EV\": exp_var_vec.mean().item(), \n",
    "                        \"St_EV_std\": exp_var_vec.std().item(),\n",
    "                        \"St_EV_rev\": exp_var_rev_vec.mean().item(), \n",
    "                        \"St_EV_rev_std\": exp_var_rev_vec.std().item(),\n",
    "                        \"Dt_EV\": exp_var_vec_Dt.mean().item(), \n",
    "                        \"Dt_EV_std\": exp_var_vec_Dt.std().item(),\n",
    "                        \"Dt_EV_rev\": exp_var_rev_vec_Dt.mean().item(),\n",
    "                        \"Dt_EV_rev_std\": exp_var_rev_vec_Dt.std().item(),\n",
    "                        \"St_Var\": St_var_vec.mean().item(),\n",
    "                        \"St_Var_std\": St_var_vec.std().item(),\n",
    "                        \"Dt_Var\": Dt_var_vec.mean().item(), \n",
    "                        \"Dt_Var_std\": Dt_var_vec.std().item(),})\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    df_syn = pd.DataFrame(df_col)\n",
    "    df_syn.to_csv(\"FFHQ_edm_5k_epoch_gmm_exp_var_part.csv\")\n",
    "\n",
    "df_syn = pd.DataFrame(df_col)\n",
    "df_syn[\"St_residual\"] = 1 - df_syn[\"St_EV\"]\n",
    "df_syn[\"St_rev_residual\"] = 1 - df_syn[\"St_EV_rev\"]\n",
    "df_syn[\"Dt_residual\"] = 1 - df_syn[\"Dt_EV\"]\n",
    "df_syn[\"Dt_rev_residual\"] = 1 - df_syn[\"Dt_EV_rev\"]\n",
    "df_syn.to_csv(\"FFHQ_edm_5k_epoch_gmm_exp_var.csv\")\n",
    "df_syn.to_csv(join(train_root, ckptname, \"FFHQ_edm_5k_epoch_gmm_exp_var.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
